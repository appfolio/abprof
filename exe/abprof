#!/usr/bin/env ruby

require "trollop"
require "abprof"
require "statsample"

OPTS = Trollop::options do
  banner <<BANNER
Specify a first and second command line, and (often) a p-value or other
parameters.

Example:  abprof examples/sleep.rb examples/sleep_longer.rb

The first and second commands are the first two arguments. You'll need to
quote multi-word commands, as is normal in bash.

Specifying lots of iterations and trials, high burn-in and a low P value
is accurate, but slow.

Specifying low iterations, trials and burn-in and a high P value gives
quick, rough results early on.

Specifying more iterations per trial is good for highly variable iteration
timing.

Specifying a lower max number of trials keeps the test from running *too*
long when the two are identical.

Specifying a high burn-in is necessary when cache behavior changes timing
significantly.

Vast numbers of trials can nearly always occasionally show differences
*somewhere* along the line, just by random chance. To avoid this, pick how
many samples first, run them all in one go, and then just check the p value
once.

A p value is often interpreted as the probability we got a wrong answer.
That's an oversimplification, but not (usually) a terrible one.
BANNER
  opt :debug1,      "Print first-process output to console"
  opt :debug2,      "Print second-process output to console"
  opt :pvalue,      "P value (certainty) for Welch's T test", :default => 0.05
  opt :burnin,      "'Burn in' repetitions before real trials",  :default => 50
  opt :min_trials,  "Minimum number of sample sets from each process", :default => 1
  opt :max_trials,  "Maximum number of sample sets from each process", :default => 20
  opt :iters_per_trial, "Iterations per sample set", :default => 100
end

if ARGV.length != 2
  puts "Must specify both commands as normal arguments!"
  exit -1
end

command1, command2 = ARGV

process1 = ABProf::ABProcess.new command1, :debug => OPTS[:debug1]
process2 = ABProf::ABProcess.new command2, :debug => OPTS[:debug2]

# Burn-in
if OPTS[:burnin] > 0
  puts "Beginning #{OPTS[:burnin]} iterations of burn-in for each process."
  process1.run_iters OPTS[:burnin]
  process2.run_iters OPTS[:burnin]
end

puts "Beginning sampling from processes."

# Sampling
samples_so_far = 0
# Statsample Vectors
results1 = []
results2 = []
p_val = 1.0
OPTS[:max_trials].times do |i|
  # Add a sample to each set, with the total time for :iters_per_trial iterations.
  results1.push process1.run_iters(OPTS[:iters_per_trial])
  results2.push process2.run_iters(OPTS[:iters_per_trial])

  # No t-test without 3+ samples
  if results1.size > 2
    # Evaluate the Welch's t-test
    t = Statsample::Test.t_two_samples_independent(results1.to_vector, results2.to_vector)
    p_val = t.probability_not_equal_variance
    puts "Trial #{i + 1}, Welch's T-test p value: #{p_val.inspect}"
  end

  break if p_val < OPTS[:pvalue] && i >= OPTS[:min_trials]
end

if p_val < OPTS[:pvalue]
  puts "Based on measured P value #{p_val}, we believe there is a speed difference."
  puts "As of end of run, p value is #{p_val}. Now run more times to check, or with lower p."

  sum1 = results1.inject(0.0, &:+)
  sum2 = results2.inject(0.0, &:+)

  fastest = "1"
  command = command1
  times = sum2 / sum1
  if sum1 > sum2
    fastest = "2"
    command = command2
    times = sum1 / sum2
  end

  puts "Lower (faster?) process is #{fastest}, command line: #{command.inspect}"
  puts "Lower command is (very) roughly #{times} times lower (faster?) -- assuming linear sampling."
else
  puts "Based on measured P value #{p_val} and threshold #{OPTS[:pvalue]}, we believe there is"
  puts "no significant difference detectable with this set of trials."
  puts "If you believe there is a small difference that wasn't detected, try raising the number"
  puts "of iterations per trial, or the maximum number of trials."
end

# Clean up processes
process1.kill
process2.kill
